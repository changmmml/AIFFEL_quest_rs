{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67d8de22",
   "metadata": {},
   "source": [
    "# [Quest] MainQuest 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b8b86395",
   "metadata": {},
   "source": [
    "## 1. Transformer와 비교해 변경이 필요한 부분을 서술하였다.\n",
    "- 제출 노트북 파일 첫부분에 텍스트 블럭으로 서술합니다. 아키텍쳐 상 변경사항을 블럭단위로 서술합니다.\n",
    "- 코드블럭에 변경사항을 주석으로 표시합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4beadab7",
   "metadata": {},
   "source": [
    "### 비교 및 아키텍쳐 상 변경사항\n",
    "1. GPT-1은 encoder를 사용하지 않는다. (Decoder-only)\n",
    "2. GPT-1의 decoder는 'Masked Multi Self Attention' - LN - 'Feed Forward' - LN - 출력 으로 이루어져있다.\\\n",
    "즉, 인코더와 디코더의 입력을 처리하는 encoder-decoder 레이어가 없다.\n",
    "3. GPT-1은 주어진 단어들을 순차적으로 처리하는 AR 모델이므로, 이전 단어들만을 고려해서 다음 단어를 예측한다.\\\n",
    "= create_padding_mask()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0797de1f",
   "metadata": {},
   "source": [
    "**GPT-1 decoder 함수 구현**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8475b1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecabe00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일드 닷 프로덕트 어텐션 함수 (변경사항 X)\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "  # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
    "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "  # 가중치를 정규화\n",
    "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "  logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "  # 패딩에 마스크 추가\n",
    "  if mask is not None:\n",
    "    logits += (mask * -1e9)\n",
    "\n",
    "  # softmax적용\n",
    "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "  # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
    "  output = tf.matmul(attention_weights, value)\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40f49842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 멀티 헤드 어텐션 함수 (변경사항 X)\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "    super(MultiHeadAttention, self).__init__(name=name)\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "  def split_heads(self, inputs, batch_size):\n",
    "    inputs = tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, inputs):\n",
    "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "        'value'], inputs['mask']\n",
    "    batch_size = tf.shape(query)[0]\n",
    "\n",
    "    # Q, K, V에 각각 Dense를 적용합니다\n",
    "    query = self.query_dense(query)\n",
    "    key = self.key_dense(key)\n",
    "    value = self.value_dense(value)\n",
    "\n",
    "    # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
    "    query = self.split_heads(query, batch_size)\n",
    "    key = self.split_heads(key, batch_size)\n",
    "    value = self.split_heads(value, batch_size)\n",
    "\n",
    "    # 스케일드 닷 프로덕트 어텐션 함수\n",
    "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "    # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "\n",
    "    # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "    outputs = self.dense(concat_attention)\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92ea5101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패딩 마스킹 (변경사항 X)\n",
    "def create_padding_mask(x):\n",
    "    \"\"\"\n",
    "    주어진 시퀀스에 대해 패딩 마스크를 생성하는 함수\n",
    "    - 패딩된 부분은 1로, 유효한 부분은 0으로 마스크\n",
    "    \"\"\"\n",
    "    padding_mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "    # (batch_size, 1, 1, sequence length)\n",
    "    return padding_mask[:, tf.newaxis, tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc6bcdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 룩 어헤드 마스킹 (변경사항 X) - AR모델 기반일 때 causal mask로 사용\n",
    "def create_look_ahead_mask(x):\n",
    "    \"\"\"\n",
    "    룩 어헤드 마스크와 패딩 마스크를 결합하는 함수.\n",
    "    - 현재 단어 이후의 단어들을 마스크하고,\n",
    "    - 패딩된 부분을 무시하는 마스크를 결합합니다.\n",
    "    \n",
    "    :param x: 입력 시퀀스\n",
    "    :return: 결합된 마스크 (Causal + Padding Mask)\n",
    "    \"\"\"\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    padding_mask = create_padding_mask(x)\n",
    "    return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fdfa9c",
   "metadata": {},
   "source": [
    "- GPT-1은 encoder를 사용하지 않는다. = Decoder-only (변경사항 O)\n",
    "- 파라미터 enc_outputs 삭제 (입력 시퀀스를 인코딩할 때 사용하는데, GPT-1는 decoder만 사용)\n",
    "- 파라미터 padding_mask 삭제 (주로 Encoder-Decoder 구조에서 필요)\\\n",
    "    GPT-1는 AR모델 기반이므로 Causal mask 사용해서 padding 처리 (2.에서 구현)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a83184",
   "metadata": {},
   "source": [
    "- GPT-1의 decoder는 'Masked Multi Self Attention' - LN - 'Feed Forward' - LN - 출력 으로 이루어져있다.\\\n",
    "즉, 인코더와 디코더의 입력을 처리하는 encoder-decoder attention 레이어가 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67dba2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 하나의 레이어 함수 (변경사항 O)\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다. (Transformer에서 인코더-디코더 어텐션 삭제)\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\") # 현재 입력 (이전 단어들의 임베딩)\n",
    "  #enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')  # 인코더 출력 (GPT-1은 사용 안 함)\n",
    "  look_ahead_mask = tf.keras.Input(shape=(1, None, None), name=\"look_ahead_mask\") # 마스크\n",
    "  #padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask') # 패딩 마스크 (GPT-1은 사용 안 함)\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention1 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': look_ahead_mask\n",
    "      })\n",
    "\n",
    "  # 드롭 아웃\n",
    "  attention1 = tf.keras.layers.Dropout(rate=dropout)(attention1)\n",
    "  # 잔차 연결 + 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention1 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "    \n",
    "  '''   \n",
    "  # Transformer에서 존재했던 레이어 삭제 (변경사항)\n",
    "  # Transformer의 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "  attention2 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "          'query': attention1,\n",
    "          'key': enc_outputs,\n",
    "          'value': enc_outputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 마스크드 멀티 헤드 어텐션의 결과는\n",
    "  # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "  attention2 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention2 + attention1)\n",
    "  '''\n",
    "\n",
    "\n",
    "  # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention1)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 잔차 연결 + LayerNormalization 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(outputs + attention1)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      #inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask], # enc_outputs, padding_mask 삭제\n",
    "      inputs=[inputs, look_ahead_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b33885f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 (변경사항 O)\n",
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "  inputs = tf.keras.Input(shape=(None,), name='inputs') # 현재 단어의 인덱스\n",
    "  #enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs') # 인코더 출력 (GPT-1은 사용 안 함) \n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name='look_ahead_mask') # 마스크\n",
    "\n",
    "\n",
    "  # 패딩 마스크 (GPT-1은 사용 안 함)\n",
    "  #padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  # Dropout\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  # Decoder Layer 반복\n",
    "  for i in range(num_layers):\n",
    "    outputs = decoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name='decoder_layer_{}'.format(i),\n",
    "    #)(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask]) # enc_outputs, padding_mask 삭제\n",
    "    )(inputs=[outputs, look_ahead_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      #inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask], # enc_outputs, padding_mask 삭제\n",
    "      inputs=[outputs, look_ahead_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221ee599",
   "metadata": {},
   "source": [
    "## 2. 모델의 입력 형태에 맞게 전처리를 수행하였다.\n",
    "- Decoder 기반의 생성모델임을 감안하여 챗봇 데이터를 변형합니다.\n",
    "- 이번 과제는 pretrain을 위한 데이터셋과 학습만 고려합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdac742",
   "metadata": {},
   "source": [
    "### 텍스트 데이터 전처리 과정\n",
    "1. 디코더 모델의 입력 데이터로 적합한 형태로 변경\n",
    "2. 텍스트 시퀀스 토큰화\n",
    "3. Causal Mask (AR 마스크)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d301b7",
   "metadata": {},
   "source": [
    "**데이터 로드 및 공백, 특수문자 처리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47d4d768",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99e6a955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문과 답변을 전처리하는 함수\n",
    "def preprocess_sentence(text):\n",
    "    \"\"\"\n",
    "    입력된 텍스트에서 공백과 특수문자를 제거하는 함수\n",
    "    - 불필요한 공백 제거\n",
    "    - 특수문자 및 숫자 제거\n",
    "    \"\"\"\n",
    "    # 단어와 구두점(punctuation) 사이 공백\n",
    "    text = re.sub(r\"([?.!,])\", r\" \\1 \", text)\n",
    "    text = re.sub(r'[\" \"]+', \" \", text)\n",
    "    # 특수문자 및 숫자 제거\n",
    "    text = re.sub(r'[^가-힣\\s]', '', text)  # 한글, 공백만 남기고 제거\n",
    "    # 불필요한 공백 제거\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # 여러 공백을 하나로 치환 후 양쪽 공백 제거\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc429338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV 파일을 로드하고, 질문, 답변, 라벨을 전처리하는 함수\n",
    "def load_conversations(file_path):\n",
    "    inputs, outputs, labels = [], [], []\n",
    "    \n",
    "    # CSV 파일을 읽어서 각 줄을 처리\n",
    "    with open(file_path, mode='r', encoding='utf-8', errors='ignore') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)  # 헤더가 있을 경우 첫 줄을 건너뛰기\n",
    "        \n",
    "        for row in reader:\n",
    "            if len(row) == 3:  # Q, A, label이 존재하는지 확인\n",
    "                question, answer, label = row\n",
    "                # 질문과 답변 전처리\n",
    "                inputs.append(preprocess_sentence(question))\n",
    "                outputs.append(preprocess_sentence(answer))\n",
    "                labels.append(label)  # 라벨도 저장\n",
    "    \n",
    "    return inputs, outputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35c21b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../aiffel/transformer_chatbot/data/ChatbotData .csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "747e0cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 수 : 11823\n",
      "전체 샘플 수 : 11823\n"
     ]
    }
   ],
   "source": [
    "questions, answers, lables = load_conversations(file_path)\n",
    "print('전체 샘플 수 :', len(questions))\n",
    "print('전체 샘플 수 :', len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bbb7788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 후의 10번째 질문 샘플: 시간낭비인데 자꾸 보게됨\n",
      "전처리 후의 10번째 답변 샘플: 시간을 정하고 해보세요\n"
     ]
    }
   ],
   "source": [
    "print('전처리 후의 10번째 질문 샘플: {}'.format(questions[9]))\n",
    "print('전처리 후의 10번째 답변 샘플: {}'.format(answers[9]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fce1c25",
   "metadata": {},
   "source": [
    "### 텍스트 시퀀스 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d84ecba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문과 답변 데이터셋에 대해서 Vocabulary 생성\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a36f0534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN의 번호 : [8144]\n",
      "END_TOKEN의 번호 : [8145]\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰에 고유한 정수를 부여\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "\n",
    "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfffba36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8146\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = tokenizer.vocab_size + 2  # 시작/종료 토큰을 고려하여 +2\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81cb559e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 10번째 질문 샘플: [772, 7594, 195, 79, 177, 362, 1251]\n",
      "정수 인코딩 후의 10번째 답변 샘플: [343, 3965, 13, 29]\n"
     ]
    }
   ],
   "source": [
    "# 임의의 22번째 샘플에 대해서 정수 인코딩 작업을 수행.\n",
    "# 각 토큰을 고유한 정수로 변환\n",
    "print('정수 인코딩 후의 10번째 질문 샘플: {}'.format(tokenizer.encode(questions[9])))\n",
    "print('정수 인코딩 후의 10번째 답변 샘플: {}'.format(tokenizer.encode(answers[9])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2658a2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문과 답변을 Subword 토큰화\n",
    "def tokenize_and_add_tokens(questions, answers):\n",
    "    tokenized_questions = []\n",
    "    tokenized_answers = []\n",
    "    \n",
    "    for question, answer in zip(questions, answers):\n",
    "        # [START]와 [END] 토큰 추가\n",
    "        tokenized_question = [START_TOKEN[0]] + tokenizer.encode(question) + [END_TOKEN[0]]\n",
    "        tokenized_answer = [START_TOKEN[0]] + tokenizer.encode(answer) + [END_TOKEN[0]]\n",
    "        \n",
    "        tokenized_questions.append(tokenized_question)\n",
    "        tokenized_answers.append(tokenized_answer)\n",
    "    \n",
    "    return tokenized_questions, tokenized_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50cea539",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions, answers = tokenize_and_add_tokens(questions, answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "925023e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10번째 질문 샘플: [8144, 772, 7594, 195, 79, 177, 362, 1251, 8145]\n",
      "10번째 질문 샘플: [8144, 343, 3965, 13, 29, 8145]\n"
     ]
    }
   ],
   "source": [
    "# 앞에 [START], 뒤에 [END] 토큰 결합 확인\n",
    "print('10번째 질문 샘플: {}'.format(questions[9]))\n",
    "print('10번째 질문 샘플: {}'.format(answers[9]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b33f88",
   "metadata": {},
   "source": [
    "## 3. 모델의 입력 블럭을 GPT 논문에 기반하여 수정하였다.\n",
    "- 모델의 input이 정상적으로 구성되었는지 확인합니다.\n",
    "- 데이터에 위치 정보를 추가하는 과정을 구현합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5fe9d0",
   "metadata": {},
   "source": [
    "### 디코더 모델에 입력 데이터로 적합한 형식으로 변환\n",
    "- GPT-1 모델 입력 데이터 형식으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d7c548e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문과 답변을 하나의 시퀀스로 결합하여 모델에 적합한 형식으로 변환\n",
    "def prepare_gpt1_input(tokenized_questions, tokenized_answers):\n",
    "    input_sequences = []\n",
    "    target_sequences = []\n",
    "    \n",
    "    for question, answer in zip(tokenized_questions, tokenized_answers):\n",
    "        # 입력: question + [END] + answer\n",
    "        input_sequence = question + answer[1:]  # answer[1:]는 [START] 토큰 제외\n",
    "        target_sequence = answer  # 모델은 answer의 시작 부분부터 예측\n",
    "        \n",
    "        input_sequences.append(input_sequence)\n",
    "        target_sequences.append(target_sequence)\n",
    "    \n",
    "    return input_sequences, target_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64e6343b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a698762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습에 사용할 입력 데이터 준비\n",
    "input_sequences, target_sequences = prepare_gpt1_input(questions, answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2308a2c1",
   "metadata": {},
   "source": [
    "적절한 max_len 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "062cac2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequences의 가장 긴 길이: 38\n",
      "Input sequences의 평균 길이: 12.925230482956948\n",
      "Target sequences의 가장 긴 길이: 29\n",
      "Target sequences의 평균 길이: 6.806140573458513\n"
     ]
    }
   ],
   "source": [
    "# Input sequences의 길이 계산\n",
    "input_lengths = [len(seq) for seq in input_sequences]\n",
    "max_input_len = max(input_lengths)\n",
    "avg_input_len = sum(input_lengths) / len(input_lengths)\n",
    "\n",
    "# Target sequences의 길이 계산\n",
    "target_lengths = [len(seq) for seq in target_sequences]\n",
    "max_target_len = max(target_lengths)\n",
    "avg_target_len = sum(target_lengths) / len(target_lengths)\n",
    "\n",
    "print(\"Input sequences의 가장 긴 길이:\", max_input_len)\n",
    "print(\"Input sequences의 평균 길이:\", avg_input_len)\n",
    "\n",
    "print(\"Target sequences의 가장 긴 길이:\", max_target_len)\n",
    "print(\"Target sequences의 평균 길이:\", avg_target_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b054e58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 각 시퀀스의 길이를 계산\n",
    "input_lengths = [len(seq) for seq in input_sequences]\n",
    "target_lengths = [len(seq) for seq in target_sequences]\n",
    "\n",
    "# 히스토그램 그리기\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Input sequences 히스토그램\n",
    "plt.subplot(1, 2, 1)  # (행, 열, 위치)\n",
    "plt.hist(input_lengths, bins=range(min(input_lengths), max(input_lengths) + 2), edgecolor='black', alpha=0.7)\n",
    "plt.title('Input Sequences Length Distribution')\n",
    "plt.xlabel('Length')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Target sequences 히스토그램\n",
    "plt.subplot(1, 2, 2)  # (행, 열, 위치)\n",
    "plt.hist(target_lengths, bins=range(min(target_lengths), max(target_lengths) + 2), edgecolor='black', alpha=0.7)\n",
    "plt.title('Target Sequences Length Distribution')\n",
    "plt.xlabel('Length')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# 전체 히스토그램 표시\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cd4a3d",
   "metadata": {},
   "source": [
    "input_sequences, target_sequences의 합일 때 적절한 max_len의 값을 40으로 그대로 잡아도 괜찮을 것 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e67c3ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LENGTH = 40  # 시퀀스 최대 길이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a435a2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "패딩된 입력 시퀀스 (10번째): [8144  772 7594  195   79  177  362 1251 8145  343 3965   13   29 8145\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "패딩된 출력 시퀀스 (10번째): [8144  343 3965   13   29 8145    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "# 입력과 출력 시퀀스에 대한 패딩 추가\n",
    "inputs = pad_sequences(input_sequences, maxlen=MAX_SEQ_LENGTH, padding='post', truncating='post')\n",
    "targets = pad_sequences(target_sequences, maxlen=MAX_SEQ_LENGTH, padding='post', truncating='post')\n",
    "\n",
    "# 패딩된 시퀀스 출력\n",
    "print(\"패딩된 입력 시퀀스 (10번째):\", inputs[9])\n",
    "print(\"패딩된 출력 시퀀스 (10번째):\", targets[9])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0b1194",
   "metadata": {},
   "source": [
    "**변형 완료**\n",
    "\n",
    "입력 시퀀스 : [START] inputs [END] target [END] [PAD] ...\n",
    "\n",
    "출력 시퀀스 : [START] target [END] [PAD] ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53fc608",
   "metadata": {},
   "source": [
    "### Causal Mask (AR 마스크)\n",
    "- 일전에 정의했던 `create_padding_mask()` 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c1632c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input에 룩 어헤드 마스크 생성 - causal mask\n",
    "look_ahead_mask = create_look_ahead_mask(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b129a583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Look-ahead Mask: (11823, 1, 40, 40)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Look-ahead Mask: {look_ahead_mask.shape}\")  # (seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14102a3a",
   "metadata": {},
   "source": [
    "### 포지셔널 인코딩 (위치 정보)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6c8dd1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 포지셔널 인코딩 레이어\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, position, d_model):\n",
    "    super(PositionalEncoding, self).__init__()\n",
    "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "  def get_angles(self, position, i, d_model):\n",
    "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "    return position * angles\n",
    "\n",
    "  def positional_encoding(self, position, d_model):\n",
    "    # 각도 배열 생성\n",
    "    angle_rads = self.get_angles(\n",
    "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "        d_model=d_model)\n",
    "\n",
    "    # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "    # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    # sin과 cosine이 교차되도록 재배열\n",
    "    pos_encoding = tf.stack([sines, cosines], axis=0)\n",
    "    pos_encoding = tf.transpose(pos_encoding,[1, 2, 0]) \n",
    "    pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
    "\n",
    "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "    return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "  def call(self, inputs):\n",
    "        # inputs가 2D 텐서일 경우, 임베딩을 통해 3D 텐서로 변환\n",
    "        if len(tf.shape(inputs)) == 2:  # (batch_size, seq_len)\n",
    "            seq_len = tf.shape(inputs)[1]\n",
    "            d_model = 512  # d_model은 여러분의 모델에 맞게 설정\n",
    "            embedding_layer = tf.keras.layers.Embedding(input_dim=5000, output_dim=d_model)  # 예시로 5000 단어사전 사용\n",
    "            inputs = embedding_layer(inputs)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "        # inputs의 시퀀스 길이에 맞춰 pos_encoding을 자르고\n",
    "        seq_len = tf.shape(inputs)[1]\n",
    "        pos_encoding = self.pos_encoding[:, :seq_len, :]\n",
    "        \n",
    "        # pos_encoding을 inputs의 batch_size에 맞게 브로드캐스트\n",
    "        batch_size = tf.shape(inputs)[0]  # inputs의 배치 크기\n",
    "        pos_encoding = tf.broadcast_to(pos_encoding, [batch_size, seq_len, tf.shape(inputs)[2]])\n",
    "\n",
    "        # pos_encoding과 inputs을 더하기 전에 dtype을 맞추기 위해 cast 처리\n",
    "        inputs = tf.cast(inputs, tf.float32)\n",
    "\n",
    "        # inputs와 pos_encoding을 더하기\n",
    "        return inputs + pos_encoding  # 여기서 pos_encoding은 이미 inputs에 맞게 브로드캐스트됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3d0ade57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 파라미터\n",
    "seq_len = 40  # 시퀀스 길이\n",
    "d_model = 512  # 모델의 차원\n",
    "\n",
    "# 포지셔널 인코딩 레이어 생성\n",
    "positional_encoding_layer = PositionalEncoding(seq_len, d_model)\n",
    "\n",
    "# inputs를 float32로 변환\n",
    "inputs = tf.cast(inputs, tf.float32)\n",
    "\n",
    "# 포지셔널 인코딩을 추가\n",
    "inputs = positional_encoding_layer(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ef530bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positional Encoded Input: (11823, 40, 512)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Positional Encoded Input: {inputs.shape}\")  # (batch_size, seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3df526",
   "metadata": {},
   "source": [
    "## 4. GPT 모델을 정상적으로 구성하였다.(model.summary, model.fit 결과 캡쳐 첨부)\n",
    "- 노드의 transformer 코드를 수정하여 GPT1 모델을 구성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9ca7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "  # 인코더에서 패딩을 위한 마스크\n",
    "  enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "\n",
    "  # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
    "  # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "  look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask,\n",
    "      output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "  # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "  # 디코더에서 패딩을 위한 마스크\n",
    "  dec_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='dec_padding_mask')(inputs)\n",
    "\n",
    "  # 인코더\n",
    "  enc_outputs = encoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "  # 디코더\n",
    "  dec_outputs = decoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "  # 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6312186",
   "metadata": {},
   "source": [
    "**모델 생성**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93efdcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68fbf86",
   "metadata": {},
   "source": [
    "**손실 함수**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f28fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  \n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "  loss = tf.multiply(loss, mask)\n",
    "\n",
    "  return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0825938",
   "metadata": {},
   "source": [
    "**커스텀 된 학습률**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ea4a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b1c1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sample_learning_rate = CustomSchedule(d_model=128)\n",
    "\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6294821",
   "metadata": {},
   "source": [
    "**모델 컴파일**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e1d6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4485805",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d91660",
   "metadata": {},
   "source": [
    "## 5. 입력에 따른 출력이 생성되었다.\n",
    "- 출력 결과물의 수준에 상관없이 모델이 정상적으로 동작하는지 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3c38e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_inference(sentence):\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
    "  # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
    "  sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "  # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "  # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
    "  output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  # 디코더의 인퍼런스 단계\n",
    "  for i in range(MAX_LENGTH):\n",
    "    # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "    predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "    predictions = predictions[:, -1:, :]\n",
    "\n",
    "    # 현재 예측한 단어의 정수\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
    "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "      break\n",
    "\n",
    "    # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "    # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "    output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output_sequence, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f597c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(sentence):\n",
    "  # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "  prediction = decoder_inference(sentence)\n",
    "\n",
    "  # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "  print('입력 : {}'.format(sentence))\n",
    "  print('출력 : {}'.format(predicted_sentence))\n",
    "\n",
    "  return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428eb509",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_generation('오늘 뭐할까?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049ef8d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
